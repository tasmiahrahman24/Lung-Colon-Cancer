{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymWP-sY-XC8y"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "HhEea8WEXQ2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "7TGeeBFEYprY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "YB2Pfjw4ZKhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "m6a162IlZeti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/lung-and-colon-cancer-histopathological-images"
      ],
      "metadata": {
        "id": "_L5RVfn1ZhnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/lung-and-colon-cancer-histopathological-images.zip"
      ],
      "metadata": {
        "id": "5TpFp-s5Z_eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ],
      "metadata": {
        "id": "8u_rHmhAcUDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/lung_colon_image_set'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(data_dir, fold)\n",
        "    flist = os.listdir(foldpath)\n",
        "\n",
        "    for f in flist:\n",
        "        f_path = os.path.join(foldpath, f)\n",
        "        filelist = os.listdir(f_path)\n",
        "\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(f_path, file)\n",
        "            filepaths.append(fpath)\n",
        "\n",
        "            if f == 'colon_aca':\n",
        "                labels.append('Colon Adenocarcinoma')\n",
        "\n",
        "            elif f == 'colon_n':\n",
        "                labels.append('Colon Benign Tissue')\n",
        "\n",
        "            elif f == 'lung_aca':\n",
        "                labels.append('Lung Adenocarcinoma')\n",
        "\n",
        "            elif f == 'lung_n':\n",
        "                labels.append('Lung Benign Tissue')\n",
        "\n",
        "            elif f == 'lung_scc':\n",
        "                labels.append('Lung Squamous Cell Carcinoma')\n",
        "\n",
        "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
        "Lseries = pd.Series(labels, name='labels')\n",
        "data = pd.concat([Fseries, Lseries], axis= 1)"
      ],
      "metadata": {
        "id": "vmDxnZnncb3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "XgiC4rF3cb1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "V7ob5yOWcbyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "q28JB13fcbvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comment"
      ],
      "metadata": {
        "id": "w8XHcuhhzqAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Assuming your dataframe is named df\n",
        "# # Replace 'file_path' with the name of your file paths column\n",
        "# # Replace 'label' with the name of your label column\n",
        "\n",
        "# # Define the number of samples you want per class\n",
        "# n_samples = 500\n",
        "\n",
        "# # Group by the label and sample n_samples from each group\n",
        "# data = data_x.groupby('labels', group_keys=False).apply(lambda x: x.sample(min(len(x), n_samples)))\n",
        "\n",
        "# # Reset the index if needed\n",
        "# data = data.reset_index(drop=True)\n",
        "\n",
        "# # Now sampled_df contains 500 files for each class\n"
      ],
      "metadata": {
        "id": "TuhdOR-ucbtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "xKFrKXtScbpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of files for each class\n",
        "class_counts = data['labels'].value_counts()\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "id": "DoxAPHoMeywW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data --> 80% train data && 20% (test, val)\n",
        "train_df, ts_df = train_test_split(data, train_size = 0.8, shuffle = True, random_state = 42)\n",
        "\n",
        "# test data --> 10% train data && 10% (test, val)\n",
        "valid_df, test_df = train_test_split(ts_df, train_size = 0.5, shuffle = True, random_state = 42)"
      ],
      "metadata": {
        "id": "lXlw2JpLe82k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "tr_gen = ImageDataGenerator(rescale=1. / 255)\n",
        "ts_gen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)"
      ],
      "metadata": {
        "id": "7o-Bx1nxfVoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie([len(train_gen), len(valid_gen), len(test_gen)],\n",
        "        labels=['train', 'validation', 'test'], autopct='%.1f%%', colors=['aqua', 'red', 'green'], explode=(0.05, 0, 0))\n",
        "plt.show()\n",
        "plt.savefig('dataset_pie.png')"
      ],
      "metadata": {
        "id": "TCt01IdYfZpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_gen.class_indices)\n",
        "print(test_gen.class_indices)\n",
        "print(valid_gen.class_indices)"
      ],
      "metadata": {
        "id": "ZeCsE8FPfbB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "# ploting the patch size samples\n",
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(batch_size):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i]\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'black', fontsize= 16)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqzR7qSSfcO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the model performance\n",
        "def model_performance(history, Epochs):\n",
        "    # Define needed variables\n",
        "    tr_acc = history.history['accuracy']\n",
        "    tr_loss = history.history['loss']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize= (20, 8))\n",
        "    plt.style.use('fivethirtyeight')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "def model_evaluation(model):\n",
        "    train_score = model.evaluate(train_gen, verbose= 1)\n",
        "    valid_score = model.evaluate(valid_gen, verbose= 1)\n",
        "    test_score = model.evaluate(test_gen, verbose= 1)\n",
        "\n",
        "    print(\"Train Loss: \", train_score[0])\n",
        "    print(\"Train Accuracy: \", train_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Validation Loss: \", valid_score[0])\n",
        "    print(\"Validation Accuracy: \", valid_score[1])\n",
        "    print('-' * 20)\n",
        "    print(\"Test Loss: \", test_score[0])\n",
        "    print(\"Test Accuracy: \", test_score[1])\n",
        "\n",
        "\n",
        "# Get Predictions\n",
        "def get_pred(model, test_gen):\n",
        "\n",
        "    preds = model.predict(test_gen)\n",
        "    y_pred = np.argmax(preds, axis = 1)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "def plot_confusion_matrix(test_gen, y_pred):\n",
        "\n",
        "    g_dict = test_gen.class_indices\n",
        "    classes = list(g_dict.keys())\n",
        "\n",
        "    # Display the confusion matrix\n",
        "    cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "    plt.figure(figsize= (10, 10))\n",
        "    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation= 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Defining a convolutional NN block for a sequential CNN model\n",
        "def conv_block(filters, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(MaxPooling2D())\n",
        "\n",
        "    return block\n",
        "\n",
        "\n",
        "# Defining a dense NN block for a sequential CNN model\n",
        "def dense_block(units, dropout_rate, act='relu'):\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Dense(units, activation=act))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(Dropout(dropout_rate))\n",
        "\n",
        "    return block"
      ],
      "metadata": {
        "id": "GavIJoxxfcM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "x-zVM8xeRH_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetB3"
      ],
      "metadata": {
        "id": "VaESrL_1RMLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))"
      ],
      "metadata": {
        "id": "byFCmaS8fcKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB3"
      ],
      "metadata": {
        "id": "bbgi2uTJgMP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ############ OLD\n",
        "# # get the pre-trained model (EfficientNetB3)\n",
        "# base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape = img_shape, pooling= None)\n",
        "\n",
        "# # fine-tune EfficientNetB3 (Adding some custom layers on top)\n",
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = dense_block(128, 0.5)(x)\n",
        "# x = dense_block(32, 0.2)(x)\n",
        "# predictions = Dense(class_counts, activation = \"sigmoid\")(x)    # output layer with softmax activation\n",
        "\n",
        "# # the model\n",
        "# EfficientNetB3_model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "iQkwe7aCfcHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# # Visualize the model\n",
        "# plot_model(EfficientNetB3_model, to_file='EfficientNetB3_model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "EuANrHVvJDZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############## NEW #########################\n",
        "# get the pre-trained model (EfficientNetB3)\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=img_shape, pooling=None)\n",
        "\n",
        "# fine-tune EfficientNetB3 (Adding some custom layers on top)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Adding an additional Dense layer with fewer units to reduce model complexity\n",
        "x = Dense(128)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "# Another Dense layer with even fewer units\n",
        "x = Dense(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "predictions = Dense(class_counts, activation=\"sigmoid\")(x)  # Output layer with sigmoid activation\n",
        "\n",
        "# the model\n",
        "EfficientNetB3_model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "KF6tZbpDctvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EfficientNetB3_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "EfficientNetB3_model.summary()"
      ],
      "metadata": {
        "id": "UjKZQc4OfcEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Visualize the model\n",
        "plot_model(EfficientNetB3_model, to_file='EfficientNetB3_model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "giUJMk6uHm3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10   # number of all epochs in training\n",
        "\n",
        "history = EfficientNetB3_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)"
      ],
      "metadata": {
        "id": "2hPOFjvOfcB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "gJB-qQQtfb-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation(EfficientNetB3_model)"
      ],
      "metadata": {
        "id": "i5w7ts7tkeBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(EfficientNetB3_model, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "TYHjDCnSkfw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AVcKN0Jok0FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "_riaZrU3k-NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xception"
      ],
      "metadata": {
        "id": "LnKCfQyCRAZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))\n",
        "\n",
        "# Load the pre-trained Xception model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=img_shape, pooling=None)"
      ],
      "metadata": {
        "id": "H82RRltcXIrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a Global Average Pooling layer\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "# Add a Dense layer with the number of classes\n",
        "output = Dense(class_counts, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "megfDnWzqqVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YGEUOYAXXIpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_gen, epochs=epochs, verbose=1, validation_data=valid_gen, shuffle=False)"
      ],
      "metadata": {
        "id": "GK7u_fEyXImq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "FNu9XpAOXIjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "model_evaluation(model)"
      ],
      "metadata": {
        "id": "uhpC8wgHXTsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(model, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "a1v2JOEnYwaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#================================\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()\n",
        "#===========================\n"
      ],
      "metadata": {
        "id": "Efvx0STeYA5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "k0N0skhJYyHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### InceptionV3"
      ],
      "metadata": {
        "id": "-1aL-CE1S4uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))\n",
        "\n",
        "# Load the pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=img_shape, pooling=None)"
      ],
      "metadata": {
        "id": "5ylI8S_YXJOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a Global Average Pooling layer\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "# Add a Dense layer with the number of classes\n",
        "output = Dense(class_counts, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model_Iv3 = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "zFicQ9eQryhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_Iv3.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_Iv3.summary()"
      ],
      "metadata": {
        "id": "Isw9NPUmXJLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10   # number of all epochs in training\n",
        "\n",
        "# Train the model\n",
        "history = model_Iv3.fit(train_gen, epochs=epochs, verbose=1, validation_data=valid_gen, shuffle=False)"
      ],
      "metadata": {
        "id": "es5XLZdXXJIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "dohSB2yiXJFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "model_evaluation(model_Iv3)"
      ],
      "metadata": {
        "id": "xcqp8M3zXpnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(model_Iv3, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "Ue3LS9zLYsoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#================================\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()\n",
        "#===========================\n"
      ],
      "metadata": {
        "id": "OuPSMjhaYhDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "jU44Et6oYuFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50"
      ],
      "metadata": {
        "id": "y7KSOoqCVZpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax"
      ],
      "metadata": {
        "id": "yHlabbb1WgvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))"
      ],
      "metadata": {
        "id": "s4J9vF-RWgmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=img_shape)\n",
        "\n",
        "# Add a Global Average Pooling layer\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "# Add a Dense layer with the number of classes\n",
        "output = Dense(class_counts, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model_resnet50 = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model_resnet50.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_resnet50.summary()"
      ],
      "metadata": {
        "id": "TAg9ZiZoWo9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model_resnet50.fit(train_gen, epochs=epochs, verbose=1, validation_data=valid_gen, shuffle=False)"
      ],
      "metadata": {
        "id": "6vew3UGPWtwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "KjbVVx2bWvgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "model_evaluation(model_resnet50)"
      ],
      "metadata": {
        "id": "TkBvNID9VbF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(model_resnet50, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "tPsBQYxIYobb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#================================\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()\n",
        "#===========================\n"
      ],
      "metadata": {
        "id": "NTwscA8jYiCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "bgNQaRRjYpwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "R9aX0b_VXuV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))\n",
        "\n",
        "# # Load the pre-trained VGG16 model\n",
        "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=img_shape, pooling=None)"
      ],
      "metadata": {
        "id": "ehak-uhTXwjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=img_shape)\n",
        "\n",
        "# Add a Global Average Pooling layer\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "# Add a Dense layer with the number of classes\n",
        "output = Dense(class_counts, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model_vgg16 = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model_vgg16.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model_vgg16.summary()"
      ],
      "metadata": {
        "id": "L5kFyZJOXwgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model_vgg16.fit(train_gen, epochs=epochs, verbose=1, validation_data=valid_gen, shuffle=False)"
      ],
      "metadata": {
        "id": "AxOR6Rz6XwdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "977FsVwiX10D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "model_evaluation(model_vgg16)"
      ],
      "metadata": {
        "id": "3foV8BzkX3lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(model_vgg16, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "zJpSzQTZYkma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#================================\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()\n",
        "#===========================\n"
      ],
      "metadata": {
        "id": "dv_sRNzrYi3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "Wq4G7uIWYl3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "QRledUvqZzkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "class_counts = len(list(train_gen.class_indices.keys()))"
      ],
      "metadata": {
        "id": "9gExPGxNZ2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "# first conv block\n",
        "cnn_model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D())\n",
        "\n",
        "# second conv block\n",
        "cnn_model.add(conv_block(32))\n",
        "\n",
        "# third conv block\n",
        "cnn_model.add(conv_block(64))\n",
        "\n",
        "# fourth conv bolck\n",
        "cnn_model.add(conv_block(128))\n",
        "\n",
        "# fifth conv block\n",
        "cnn_model.add(conv_block(256))\n",
        "\n",
        "# flatten layer\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# first dense block\n",
        "cnn_model.add(dense_block(128, 0.5))\n",
        "\n",
        "# second dense block\n",
        "cnn_model.add(dense_block(64, 0.3))\n",
        "\n",
        "# third dense block\n",
        "cnn_model.add(dense_block(32, 0.2))\n",
        "\n",
        "# output layer\n",
        "cnn_model.add(Dense(class_counts, activation = \"sigmoid\"))"
      ],
      "metadata": {
        "id": "D_zg2pf9Z27a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(Adamax(learning_rate= 0.001), loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "HZ6Be4JCZ24a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10   # number of all epochs in training\n",
        "\n",
        "history = cnn_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)"
      ],
      "metadata": {
        "id": "9GLA4fwbZ-Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performance\n",
        "model_performance(history, epochs)"
      ],
      "metadata": {
        "id": "GyvYNeJUZ-Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "model_evaluation(cnn_model)"
      ],
      "metadata": {
        "id": "Jyha_UR9aKua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "y_pred = get_pred(cnn_model, test_gen)\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(test_gen, y_pred)"
      ],
      "metadata": {
        "id": "lJ_Gp5RcaKr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#================================\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()\n",
        "#===========================\n"
      ],
      "metadata": {
        "id": "ONWzwUbOaKpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "8n2q6T1JaTWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explainable AI\n"
      ],
      "metadata": {
        "id": "ZNqmFfWPlJ1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "rRj5G0xllNaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict=test_gen.class_indices\n",
        "classes=list(test_dict.keys())\n",
        "x_batch,labels=next(valid_gen) # get a sample batch from the generator\n",
        "plt.figure(figsize=(20, 20))\n",
        "length=len(labels)\n",
        "if length<25:   #show maximum of 25 images\n",
        "    r=length\n",
        "else:\n",
        "    r=25\n",
        "for i in range(r):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    #image=(images[i]+1 )/2 # scale images between 0 and 1 becaue pre-processor set them between -1 and +1\n",
        "    plt.imshow(x_batch[i])\n",
        "    index=np.argmax(labels[i])\n",
        "    class_name=classes[index]\n",
        "    plt.title(class_name, color='blue', fontsize=16)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MnMvbnldmK2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "fig,ax=plt.subplots(4,3)\n",
        "fig.set_size_inches(30,30)\n",
        "for next_element in test_gen:\n",
        "    x_batch, y_batch = next_element\n",
        "    print(y_batch)\n",
        "    for i in range (0,4):\n",
        "        for j in range(3):\n",
        "            random_example = np.random.randint(0, batch_size)\n",
        "            ax[i,j].imshow(x_batch[random_example])\n",
        "            ax[i,j].set_title(class_name)\n",
        "    break"
      ],
      "metadata": {
        "id": "_QhkwXvElTEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LIME"
      ],
      "metadata": {
        "id": "en9egwgjnm1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "M6rKvTu2nmXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "from lime import lime_image\n",
        "explainer = lime_image.LimeImageExplainer()"
      ],
      "metadata": {
        "id": "Ep3kkHYdnmUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explanation = explainer.explain_instance(x_batch[9], EfficientNetB3_model.predict, top_labels=5, hide_color=0, num_samples=10000)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v7HW-l47n78_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.segmentation import mark_boundaries\n",
        "temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10000, hide_rest=True)\n",
        "temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10000, hide_rest=True)\n",
        "#plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "fig, (ax,ax1, ax2) = plt.subplots(1, 3, figsize=(15,15))\n",
        "ax.imshow(x_batch[9])\n",
        "ax1.imshow(mark_boundaries(temp_1, mask_1))\n",
        "ax2.imshow(mark_boundaries(temp_2, mask_2))\n",
        "\n",
        "ax.axis('off')\n",
        "ax1.axis('off')\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.savefig('mask_default.png')"
      ],
      "metadata": {
        "id": "ulYldn9DnmRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "img_path = \"/content/lung_colon_image_set/colon_image_sets/colon_aca/colonca1009.jpeg\"\n",
        "img = plt.imread(img_path)\n",
        "\n",
        "def predict_fn(images):\n",
        "\n",
        "    return np.random.rand(len(images), 5)\n",
        "\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "explanation = explainer.explain_instance(img, predict_fn, top_labels=5, hide_color=0, num_samples=1000)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
        "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
        "plt.axis('off')\n",
        "plt.title('LIME Explanation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6z_bwkYJJfMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP"
      ],
      "metadata": {
        "id": "nechO_TUqhXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "1DchQHnCt23Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "# Define the dataset directory\n",
        "# dataset_dir = \"/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set\"\n",
        "\n",
        "# Define the path to the image you want to explain\n",
        "image_path = \"/content/lung_colon_image_set/lung_image_sets/lung_aca/lungaca1000.jpeg\"\n",
        "\n",
        "# Define the preprocess function\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])  # Resize image to (128, 128)\n",
        "    image = tf.cast(image, tf.float32)    # Normalize pixel values\n",
        "    return image.numpy()\n",
        "\n",
        "# Preprocess the image\n",
        "image = preprocess_image(image_path)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "# model = ResNet50(weights=\"imagenet\")\n",
        "\n",
        "def f(x):\n",
        "    tmp = x.copy()\n",
        "    preprocess_input(tmp)\n",
        "    return EfficientNetB3_model(tmp)\n",
        "\n",
        "# Create an Image masker for SHAP\n",
        "masker_blur = shap.maskers.Image(\"blur(224,224)\", shape=(224, 224, 3))\n",
        "\n",
        "# Create the SHAP explainer\n",
        "explainer_blur = shap.Explainer(f, masker_blur)\n",
        "\n",
        "# Explain predictions on the image\n",
        "shap_values_fine = explainer_blur(image[np.newaxis, :, :, :], max_evals=500, outputs=shap.Explanation.argsort.flip[:4])\n",
        "\n",
        "# Plot the SHAP values\n",
        "shap.image_plot(shap_values_fine)"
      ],
      "metadata": {
        "id": "BqewQg4RtrXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])  # Resize image to (128, 128)\n",
        "    image = tf.cast(image, tf.float32) / 255.0   # Normalize pixel values\n",
        "    return image.numpy()\n",
        "\n",
        "image = preprocess_image(image_path)\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "# model = ResNet50(weights=\"imagenet\")\n",
        "\n",
        "def f(x):\n",
        "    tmp = x.copy()\n",
        "    preprocess_input(tmp)\n",
        "    return EfficientNetB3_model(tmp)\n",
        "\n",
        "# Create an Image masker for SHAP\n",
        "masker_blur = shap.maskers.Image(\"blur(224,224)\", shape=(224, 224, 3))\n",
        "\n",
        "# Create the SHAP explainer\n",
        "explainer_blur = shap.Explainer(f, masker_blur)\n",
        "\n",
        "# Explain predictions on the image\n",
        "shap_values_fine = explainer_blur(image[np.newaxis, :, :, :], max_evals=5000, outputs=shap.Explanation.argsort.flip[2:8:2])\n",
        "\n",
        "# Plot the SHAP values\n",
        "shap.image_plot(shap_values_fine)"
      ],
      "metadata": {
        "id": "8GHJP1KvK7Vp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}